{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP0voU-0UtdQ",
        "outputId": "92b92912-dd81-464e-f60c-f3b55a967819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlMfHBIeUYCo",
        "outputId": "bfc1dcaa-bc72-425b-8e4e-ee923e1bdd2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-28 21:23:06,048] A new study created in memory with name: no-name-2fb2381d-5e31-4573-b4e7-79b333594c68\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Optuna hyperparameter tuning (this will take 30–60 seconds)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-28 21:23:06,378] Trial 0 finished with value: 0.7588653053145651 and parameters: {'max_depth': 6, 'eta': 0.2348583284433932, 'subsample': 0.698944536152778, 'colsample_bytree': 0.5211833892988962, 'min_child_weight': 7, 'lambda': 3.2371892104652122, 'alpha': 8.192697039681098}. Best is trial 0 with value: 0.7588653053145651.\n",
            "[I 2025-11-28 21:23:06,763] Trial 1 finished with value: 0.7550788067844494 and parameters: {'max_depth': 6, 'eta': 0.09002447617931815, 'subsample': 0.7220018565666114, 'colsample_bytree': 0.8658371883257701, 'min_child_weight': 9, 'lambda': 5.518848967871336, 'alpha': 2.0349555101336114}. Best is trial 0 with value: 0.7588653053145651.\n",
            "[I 2025-11-28 21:23:07,062] Trial 2 finished with value: 0.7643462443934446 and parameters: {'max_depth': 5, 'eta': 0.06670489904761134, 'subsample': 0.6217369759869346, 'colsample_bytree': 0.7885311381706236, 'min_child_weight': 9, 'lambda': 5.216314475262835, 'alpha': 3.8482387506986453}. Best is trial 2 with value: 0.7643462443934446.\n",
            "[I 2025-11-28 21:23:07,331] Trial 3 finished with value: 0.7613517300279797 and parameters: {'max_depth': 4, 'eta': 0.27075067376068684, 'subsample': 0.5607417698505754, 'colsample_bytree': 0.56437656248003, 'min_child_weight': 1, 'lambda': 1.0450613675337042, 'alpha': 8.4570419042067}. Best is trial 2 with value: 0.7643462443934446.\n",
            "[I 2025-11-28 21:23:07,840] Trial 4 finished with value: 0.7541797558961258 and parameters: {'max_depth': 8, 'eta': 0.08052732802304798, 'subsample': 0.6346526184816442, 'colsample_bytree': 0.552847941755021, 'min_child_weight': 6, 'lambda': 7.932807139566404, 'alpha': 1.8353781957693418}. Best is trial 2 with value: 0.7643462443934446.\n",
            "[I 2025-11-28 21:23:08,038] Trial 5 finished with value: 0.7686865487766582 and parameters: {'max_depth': 3, 'eta': 0.13698528115274064, 'subsample': 0.7442201293750383, 'colsample_bytree': 0.6066572152248643, 'min_child_weight': 5, 'lambda': 7.496444354932843, 'alpha': 7.955698632638962}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:08,401] Trial 6 finished with value: 0.7634915165488004 and parameters: {'max_depth': 6, 'eta': 0.07023886620608283, 'subsample': 0.58289450230527, 'colsample_bytree': 0.7264831021397059, 'min_child_weight': 5, 'lambda': 7.494926542287499, 'alpha': 5.278633708411729}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:08,702] Trial 7 finished with value: 0.7668167251947556 and parameters: {'max_depth': 4, 'eta': 0.08184916329952004, 'subsample': 0.6215933190109838, 'colsample_bytree': 0.7605059591229566, 'min_child_weight': 10, 'lambda': 7.488614623984229, 'alpha': 7.909520347078376}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:08,896] Trial 8 finished with value: 0.7645796240518403 and parameters: {'max_depth': 3, 'eta': 0.16276828294473225, 'subsample': 0.6412867938942703, 'colsample_bytree': 0.7457400176596646, 'min_child_weight': 4, 'lambda': 6.866012590316836, 'alpha': 0.6036770855467619}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:09,095] Trial 9 finished with value: 0.7652518998796621 and parameters: {'max_depth': 3, 'eta': 0.20141922036293367, 'subsample': 0.6670673954191788, 'colsample_bytree': 0.6306292671101055, 'min_child_weight': 3, 'lambda': 9.113211411859124, 'alpha': 0.3580474092983554}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:09,520] Trial 10 finished with value: 0.768158696929347 and parameters: {'max_depth': 8, 'eta': 0.017675556065490622, 'subsample': 0.8408186126556424, 'colsample_bytree': 0.6408312301494394, 'min_child_weight': 2, 'lambda': 3.224696506280935, 'alpha': 9.945140968998741}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:11,602] Trial 11 finished with value: 0.7667993365268628 and parameters: {'max_depth': 8, 'eta': 0.026105522068723824, 'subsample': 0.8460284795070168, 'colsample_bytree': 0.6493757998511669, 'min_child_weight': 2, 'lambda': 3.034118302057557, 'alpha': 9.87712482112518}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:12,090] Trial 12 finished with value: 0.7552671926196921 and parameters: {'max_depth': 7, 'eta': 0.1424725182055762, 'subsample': 0.8200620290788802, 'colsample_bytree': 0.644229374552613, 'min_child_weight': 1, 'lambda': 3.436375787664809, 'alpha': 6.442401326573237}. Best is trial 5 with value: 0.7686865487766582.\n",
            "[I 2025-11-28 21:23:12,486] Trial 13 finished with value: 0.7696091801434004 and parameters: {'max_depth': 7, 'eta': 0.01174946323078028, 'subsample': 0.7758616614156305, 'colsample_bytree': 0.5984528995589233, 'min_child_weight': 4, 'lambda': 0.44736226285617686, 'alpha': 9.939654562767284}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:12,909] Trial 14 finished with value: 0.7582997866198897 and parameters: {'max_depth': 7, 'eta': 0.13924078969384535, 'subsample': 0.7759468604694939, 'colsample_bytree': 0.5837520033450455, 'min_child_weight': 7, 'lambda': 0.1754871218919627, 'alpha': 6.785032116615015}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:13,217] Trial 15 finished with value: 0.7639779864624319 and parameters: {'max_depth': 5, 'eta': 0.18984757715429504, 'subsample': 0.8949630456202183, 'colsample_bytree': 0.5097954151601102, 'min_child_weight': 4, 'lambda': 9.805707013846817, 'alpha': 8.928352021501272}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:13,614] Trial 16 finished with value: 0.745065204408693 and parameters: {'max_depth': 7, 'eta': 0.29787099042691423, 'subsample': 0.7550928431573126, 'colsample_bytree': 0.68042738526064, 'min_child_weight': 5, 'lambda': 1.451507222455067, 'alpha': 6.864424285071841}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:13,900] Trial 17 finished with value: 0.766424370801114 and parameters: {'max_depth': 4, 'eta': 0.1188482567603293, 'subsample': 0.7678838764878517, 'colsample_bytree': 0.5910220952045139, 'min_child_weight': 7, 'lambda': 6.13101596801798, 'alpha': 5.781281687328136}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:14,213] Trial 18 finished with value: 0.768476749596681 and parameters: {'max_depth': 5, 'eta': 0.03439495679891512, 'subsample': 0.7128044868934523, 'colsample_bytree': 0.6826440800554856, 'min_child_weight': 6, 'lambda': 4.294520005031517, 'alpha': 4.0597164511225765}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:14,430] Trial 19 finished with value: 0.7681294406246133 and parameters: {'max_depth': 3, 'eta': 0.11741631860353015, 'subsample': 0.5145187263596442, 'colsample_bytree': 0.606192735038721, 'min_child_weight': 4, 'lambda': 1.7957309790998004, 'alpha': 9.230477841909622}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:14,835] Trial 20 finished with value: 0.7550054338297203 and parameters: {'max_depth': 7, 'eta': 0.1837442326067637, 'subsample': 0.7556935304374849, 'colsample_bytree': 0.8166185016594132, 'min_child_weight': 3, 'lambda': 9.031697147426925, 'alpha': 7.511939160956149}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:15,181] Trial 21 finished with value: 0.7680916705804071 and parameters: {'max_depth': 5, 'eta': 0.04116393604377158, 'subsample': 0.7085570668375099, 'colsample_bytree': 0.6760819295669962, 'min_child_weight': 6, 'lambda': 4.464106850593868, 'alpha': 4.1516320392098045}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:15,434] Trial 22 finished with value: 0.7687464029450729 and parameters: {'max_depth': 4, 'eta': 0.04250131301593425, 'subsample': 0.7991841106230545, 'colsample_bytree': 0.7048988282512985, 'min_child_weight': 5, 'lambda': 4.257970026497996, 'alpha': 3.9094780775639615}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:15,700] Trial 23 finished with value: 0.7678094788157007 and parameters: {'max_depth': 4, 'eta': 0.05104060642535615, 'subsample': 0.8060453502603783, 'colsample_bytree': 0.7179525120711376, 'min_child_weight': 5, 'lambda': 2.2379389412817012, 'alpha': 3.0703091746258}. Best is trial 13 with value: 0.7696091801434004.\n",
            "[I 2025-11-28 21:23:15,906] Trial 24 finished with value: 0.7697152664970729 and parameters: {'max_depth': 3, 'eta': 0.015412006804828274, 'subsample': 0.8840462863313182, 'colsample_bytree': 0.5407486695380321, 'min_child_weight': 3, 'lambda': 0.14603740382266173, 'alpha': 4.706843321494689}. Best is trial 24 with value: 0.7697152664970729.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Parameters: {'max_depth': 3, 'eta': 0.015412006804828274, 'subsample': 0.8840462863313182, 'colsample_bytree': 0.5407486695380321, 'min_child_weight': 3, 'lambda': 0.14603740382266173, 'alpha': 4.706843321494689}\n",
            "\n",
            "AUC = 0.7695\n",
            "Brier Score = 0.1379 (lower is better)\n",
            "\n",
            "Adverse Action Reasons:\n",
            "- Sex (SHAP +0.081)\n",
            "- High credit utilization pattern (SHAP +0.078)\n",
            "- Age (SHAP +0.072)\n",
            "- Marriage (SHAP +0.029)\n",
            "\n",
            "--- GPT-4o Advanced Underwriting Narrative ---\n",
            "\n",
            "### 1. Regulator-Aligned Underwriting Narrative\n",
            "\n",
            "The borrower has a credit limit of $230,000 and is currently exhibiting a probability of default estimated at 11.51%. The key risk factors identified include the borrower's gender, high credit utilization, age, and marital status. The borrower is utilizing a significant portion of their available credit, which indicates a higher risk of financial strain. Additionally, the borrower's age and marital status contribute to the risk profile, as these factors can influence financial stability and repayment behavior. Overall, while the borrower has no recent delinquencies, the combination of these factors suggests a moderate risk level that requires careful monitoring.\n",
            "\n",
            "### 2. Borrower-Friendly Improvement Steps\n",
            "\n",
            "1. **Reduce Credit Utilization**: Aim to lower the balance on your credit accounts to reduce your credit utilization ratio. Keeping this ratio below 30% can positively impact your credit profile.\n",
            "\n",
            "2. **Increase Monthly Payments**: Consider increasing the amount you pay each month towards your outstanding balances. This can help reduce your overall debt faster and improve your creditworthiness.\n",
            "\n",
            "3. **Review and Adjust Spending Habits**: Evaluate your monthly expenses and identify areas where you can cut back. Redirect these savings towards paying down your credit card balances.\n",
            "\n",
            "4. **Set Up Automatic Payments**: To ensure timely payments and avoid potential delinquencies, set up automatic payments for at least the minimum amount due on your credit accounts.\n",
            "\n",
            "5. **Seek Financial Advice**: Consider consulting with a financial advisor to develop a personalized plan for managing your debt and improving your credit profile.\n",
            "\n",
            "### 3. Model Risk Management (MRM) Note\n",
            "\n",
            "- **Anomalous SHAP Patterns**: The SHAP values indicate that gender, high credit utilization, age, and marital status are significant risk drivers. These patterns appear consistent with typical credit risk factors and do not show any anomalies.\n",
            "\n",
            "- **Potential Drift Signals**: There is no immediate evidence of model drift based on the provided data. However, continuous monitoring is recommended to ensure that the model remains aligned with current borrower behaviors and economic conditions.\n",
            "\n",
            "- **Consistency with Credit Policy**: The identified risk drivers are consistent with standard credit policy guidelines, which typically consider factors such as credit utilization, age, and marital status in assessing credit risk.\n",
            "\n",
            "### 4. Fair Lending Compliance Note\n",
            "\n",
            "- **Protected-Class Features**: The model does not use protected-class features such as race or gender directly in its decision-making process. However, gender is noted as a risk driver, which requires careful consideration to ensure it does not lead to discriminatory outcomes.\n",
            "\n",
            "- **Explanation Proxy**: The explanation provided does not improperly proxy for race, gender, or age. The focus is on credit utilization, financial behavior, and demographic factors that are relevant to credit risk assessment, ensuring compliance with fair lending practices.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Advanced LLM-Augmented Credit Risk Pipeline (XGBoost + Optuna + WOE + SHAP + GPT-4o)\n",
        "\n",
        "Dataset: UCI Default of Credit Card Clients (30,000 observations)\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import optuna\n",
        "import openai\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "\n",
        "\n",
        "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "df = pd.read_excel(URL, header=1)\n",
        "\n",
        "df.rename(columns={\"default payment next month\": \"target\"}, inplace=True)\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "\n",
        "# Add debt-to-income proxy (using bill amounts / income)\n",
        "df[\"income_log\"] = np.log(df[\"LIMIT_BAL\"] + 1)\n",
        "df[\"avg_bill\"] = df[[f\"BILL_AMT{i}\" for i in range(1,7)]].mean(axis=1)\n",
        "df[\"avg_pay_amt\"] = df[[f\"PAY_AMT{i}\" for i in range(1,7)]].mean(axis=1)\n",
        "\n",
        "# Utilization (bill / credit limit)\n",
        "df[\"utilization\"] = df[\"avg_bill\"] / (df[\"LIMIT_BAL\"] + 1)\n",
        "\n",
        "# Payment consistency (variance of payments)\n",
        "df[\"pay_var\"] = df[[f\"PAY_AMT{i}\" for i in range(1,7)]].var(axis=1)\n",
        "\n",
        "# Next-month delinquency signal: PAY_0 is most predictive\n",
        "df[\"delq_severity\"] = df[\"PAY_0\"].clip(lower=0)\n",
        "\n",
        "\n",
        "\n",
        "bin_cols = [\"utilization\", \"avg_bill\", \"avg_pay_amt\", \"pay_var\"]\n",
        "\n",
        "woe_transformers = {}\n",
        "for col in bin_cols:\n",
        "    kb = KBinsDiscretizer(n_bins=8, encode=\"ordinal\", strategy=\"quantile\")\n",
        "    df[col + \"_bin\"] = kb.fit_transform(df[[col]])\n",
        "    woe_transformers[col] = kb\n",
        "\n",
        "# Replace bins with numeric codes\n",
        "bin_features = [col + \"_bin\" for col in bin_cols]\n",
        "\n",
        "\n",
        "model_features = [\n",
        "    \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\",\n",
        "    \"delq_severity\", \"income_log\"\n",
        "] + bin_features\n",
        "\n",
        "X = df[model_features]\n",
        "y = df[\"target\"]\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# 5. TRAIN / TEST SPLIT\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
        "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 0.9),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10.0),\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 10.0),\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        tree_method=\"hist\",\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, preds)\n",
        "    return auc\n",
        "\n",
        "\n",
        "print(\"\\nRunning Optuna hyperparameter tuning (this will take 30–60 seconds)...\")\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=25)\n",
        "\n",
        "print(\"\\nBest Parameters:\", study.best_params)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_params = study.best_params\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    tree_method=\"hist\",\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "cal_model = CalibratedClassifierCV(model, cv=3, method=\"sigmoid\")\n",
        "cal_model.fit(X_train, y_train)\n",
        "\n",
        "test_proba = cal_model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, test_proba)\n",
        "brier = brier_score_loss(y_test, test_proba)\n",
        "\n",
        "print(f\"\\nAUC = {auc:.4f}\")\n",
        "print(f\"Brier Score = {brier:.4f} (lower is better)\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fitted_xgb = cal_model.calibrated_classifiers_[0].estimator\n",
        "\n",
        "explainer = shap.TreeExplainer(fitted_xgb)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# pick one borrower\n",
        "idx = X_test.index[5]\n",
        "x_row = X_test.loc[idx]\n",
        "shap_row = shap_values[X_test.index.get_loc(idx)]\n",
        "prob_default = float(test_proba[X_test.index.get_loc(idx)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "REASON_DICT = {\n",
        "    \"utilization_bin\": \"High credit utilization pattern\",\n",
        "    \"avg_bill_bin\": \"Elevated outstanding balance levels\",\n",
        "    \"avg_pay_amt_bin\": \"Low payment capacity\",\n",
        "    \"pay_var_bin\": \"Inconsistent payment behavior\",\n",
        "    \"delq_severity\": \"Recent delinquency severity\",\n",
        "}\n",
        "\n",
        "def build_adverse_reasons(x_row, shap_row, top_k=4):\n",
        "    pairs = sorted(zip(x_row.index, shap_row), key=lambda x: -x[1])[:top_k]\n",
        "    reasons = []\n",
        "    for f, c in pairs:\n",
        "        readable = REASON_DICT.get(f, f.replace(\"_\", \" \").title())\n",
        "        reasons.append(f\"{readable} (SHAP {c:+.3f})\")\n",
        "    return reasons\n",
        "\n",
        "reasons = build_adverse_reasons(x_row, shap_row)\n",
        "\n",
        "print(\"\\nAdverse Action Reasons:\")\n",
        "for r in reasons:\n",
        "    print(\"-\", r)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_underwriting_prompt(features, shap_row, reasons, prob):\n",
        "    feat_str = \"\\n\".join([f\"- {k}: {v}\" for k, v in features.items()])\n",
        "    reasons_str = \"\\n\".join([f\"- {r}\" for r in reasons])\n",
        "\n",
        "    return f\"\"\"\n",
        "You are an expert senior credit underwriter AND a model-risk governance reviewer.\n",
        "You have access to borrower data, risk estimates, model explanations, and credit policy rules.\n",
        "\n",
        "Borrower Snapshot:\n",
        "{feat_str}\n",
        "\n",
        "Model Estimated Probability of Default: {prob:.2%}\n",
        "\n",
        "Principal Risk Drivers:\n",
        "{reasons_str}\n",
        "\n",
        "TASKS:\n",
        "1. Provide a **regulator-aligned underwriting narrative** explaining the risk in plain language\n",
        "   without referencing SHAP or model internals.\n",
        "2. Provide **4–6 borrower-friendly improvement steps** (credit behavior, balances, utilization).\n",
        "3. Provide a **Model Risk Management (MRM) note**:\n",
        "   - Check for anomalous SHAP patterns\n",
        "   - Check for potential drift signals\n",
        "   - Check if risk drivers are consistent with credit policy\n",
        "4. Provide a **Fair Lending Compliance note** ensuring:\n",
        "   - No protected-class features are used\n",
        "   - Explanation does not proxy for race, gender, age improperly\n",
        "\n",
        "Answer in structured sections.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "def call_gpt_4o(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "prompt = make_underwriting_prompt(x_row, shap_row, reasons, prob_default)\n",
        "\n",
        "print(\"\\n--- GPT-4o Advanced Underwriting Narrative ---\\n\")\n",
        "print(call_gpt_4o(prompt))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
